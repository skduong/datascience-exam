{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"clearfix\" style=\"padding: 10px; padding-left: 0px\">\n",
    "<a href=\"http://bombora.com\"><img src=\"https://app.box.com/shared/static/e0j9v1xjmubit0inthhgv3llwnoansjp.png\" width=\"200px\" class=\"pull-right\" style=\"display: inline-block; margin: 5px; vertical-align: middle;\"></a>\n",
    "<h1> Bombora Data Science: <br> *Interview Exam* </h1>\n",
    "</div>\n",
    "\n",
    "<img width=\"200px\" src=\"https://app.box.com/shared/static/15slg1mvjd1zldbg3xkj9picjkmhzpa5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Welcome\n",
    "\n",
    "Welcome! This notebook contains interview exam questions referenced in the *Instructions* section in the `README.md`â€”please read that first, *before* attempting to answer questions here.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p style=\"font-weight:bold\">ADVICE</p>\n",
    "<p>*Do not* read these questions, and panic, *before* reading the instructions in `README.md`.</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p style=\"font-weight:bold\">WARNING</p>\n",
    "\n",
    "<p>If using <a href=\"https://try.jupyter.org\">try.jupyter.org</a> do not rely on the server for anything you want to last - your server will be <span style=\"font-weight:bold\">deleted after 10 minutes of inactivity</span>. Save often and rember download notebook when you step away (you can always re-upload and start again)!</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "## Have fun!\n",
    "\n",
    "Regardless of outcome, getting to know you is important. Give it your best shot and we'll look forward to following up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algo + Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1.1: Fibionacci\n",
    "![fib image](https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/Fibonacci_spiral_34.svg/200px-Fibonacci_spiral_34.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 1.1.1\n",
    "Given $n$ where $n \\in \\mathbb{N}$ (i.e., $n$ is an integer and $n > 0$), write a function `fibonacci(n)` that computes the Fibonacci number $F_n$, where $F_n$ is defined by the recurrence relation:\n",
    "\n",
    "$$ F_n = F_{n-1} + F_{n-2}$$\n",
    "\n",
    "with initial conditions of:\n",
    "\n",
    "$$ F_1 = 1,  F_2 = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive\n",
    "def fibonacci(n):\n",
    "    if n == 1 or n == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci(n-1)+fibonacci(n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 1.1.2\n",
    "What's the complexity of your implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complexity: O(2^n)  \n",
    "the function calls itself twice for each run, so for n calls, it is O(2^n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 1.1.3\n",
    "Consider an alternative implementation to compute Fibonacci number $F_n$ and write a new function, `fibonacci2(n)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterative\n",
    "def fibonacci2(n):\n",
    "    f = [1,1]\n",
    "    for i in range(2, n):\n",
    "        f.append(f[-2]+f[-1])\n",
    "    return f[n-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 1.1.4\n",
    "What's the complexity of your implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complexity = O(n)  \n",
    "appending to the list costs O(1); doing it n times is O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 1.1.5\n",
    "What are some examples of optimizations that could improve computational performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the function were to be called repeatedly, then memoization could be used to cache previously calculated values and avoid repetitive computations.  \n",
    "\n",
    "The nth Fibonacci number could also be directly calculated through Binet's Formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prob + Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.2: Making a 6-side die roll a 7?\n",
    "\n",
    "Using a single 6-side die, how can you generate a random number between 1 - 7?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By rolling the die twice, we end up with 36 pairs: {(1,1), (1,2), (1,3), ..., (6,6)} that have an equal chance of appearing.\n",
    "- Discard one of these pair by having it indicate a re-roll. There is now 35 equally-likely results.\n",
    "- Map 5 of these unique pairs for each number from 1 to 7, simulating a 5/35 = 1/7 chance of \"rolling\" any of the numbers.\n",
    "\n",
    "This solution suffices for general purposes but may not be practical for simulating a large number of rolls (due to the chance of constantly re-rolling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing this idea with a simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/36 ~  0.027777777777777776 \n",
      "35/36 * 1/7 ~  0.1388888888888889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Results</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27391</td>\n",
       "      <td>0.027391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138780</td>\n",
       "      <td>0.138780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138807</td>\n",
       "      <td>0.138807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138465</td>\n",
       "      <td>0.138465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139687</td>\n",
       "      <td>0.139687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>138634</td>\n",
       "      <td>0.138634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>138602</td>\n",
       "      <td>0.138602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>139634</td>\n",
       "      <td>0.139634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Results         %\n",
       "0    27391  0.027391\n",
       "1   138780  0.138780\n",
       "2   138807  0.138807\n",
       "3   138465  0.138465\n",
       "4   139687  0.139687\n",
       "5   138634  0.138634\n",
       "6   138602  0.138602\n",
       "7   139634  0.139634"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def diceRoll(): #give random number from 1 to 6\n",
    "    return str(random.randint(1,6))\n",
    "\n",
    "def roll7():\n",
    "    m = {1: [11, 12, 13, 14, 15],\n",
    "         2: [16, 21, 22, 23, 24],\n",
    "         3: [25, 26, 31, 32, 33],\n",
    "         4: [34, 35, 36, 41, 42],\n",
    "         5: [43, 44, 45, 46, 51],\n",
    "         6: [52, 53, 54, 55, 56],\n",
    "         7: [61, 62, 63, 64, 65]}\n",
    "    \n",
    "    d1 = diceRoll(); d2 = diceRoll() #roll twice\n",
    "    \n",
    "    for i in range(1,8):\n",
    "        if int(d1+d2) in m[i]: \n",
    "            return i\n",
    "    return 0 #indicates re-roll\n",
    "\n",
    "results = [] #keep track of each result\n",
    "rolls = 1000000 #simulate 1000000 rolls of the \"7-sided die\" \n",
    "for i in range(rolls): \n",
    "    results.append(roll7())\n",
    "\n",
    "total = np.unique(results, return_counts=True)[1]\n",
    "chance = total/rolls\n",
    "print ('1/36 ~ ', 1/36, '\\n35/36 * 1/7 ~ ', 35/36/7)\n",
    "pd.DataFrame({'Results': total, '%':chance})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Conceptual ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.2 Model Selection and Assesment\n",
    "\n",
    "Consider a multiclass classification problem with a large number of features $p >> N$, for e.g $p=10000, N=100$ The task is threefold\n",
    "1. Find a \"good\" subset of features that show strong _univariate_ correlation with class labels\n",
    "2. Using the \"good\" subset, build a multi class classifier\n",
    "3. Estimate the generalization error of the final model\n",
    "\n",
    "Given this dataset, outline your approach and please be sure to cover the following\n",
    "- Data splitting\n",
    "- Model Selection: either estimating the performance of different classifiers or the same classifier with different hyperparameters\n",
    "- Model Assessment: having chosen a classifier, estimating the generalization error\n",
    "\n",
    "Assume all features are numerical, the dataset contains no NULLS, outliers, etc. and doesn't require any preprocessing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get some idea of what these features are and their relationship, I would start by looking at their distributions and correlations, taking note of any patterns or outliers that may appear since it could affect which models are more effective. For instance, if high multicolinearity is present, logistic regression would probably not be an ideal choice (or if chosen, would require further analysis such using VIF). \n",
    "To get a \"good\" subset of features, selecting features that have a high Pearson Correlation coefficient against the response would be a possible choice. Seeing that the size of p is rather extreme, this simple solution may not suffice (for instance, it may be the case that thousands of features end up having r<-0.8 or r>0.8). Rather than just removing features, dimension reduction through PCA may also be considered. Through this method, the features are compressed through their linear combinations, resulting in less redundancy while still explaining a high proportion of the data variance. Since this is a classification task, I would also look at the class balance and possibly rebalance through SMOTE if necessary. \n",
    "\n",
    "With only N=100, the data is insufficient for machine learning models such as MLPs and would lead to poor generalization. Even with less complex models like random forest, overfitting may still be a problem with so little cases and possibly high number of features to train on. Simpler classifiers may be the best choice in this case, so I would try KNN, SVM, and Logistic Regression and compare their results to determine the best one. \n",
    "For a concrete example, suppose KNN is chosen. The data will be rescaled if needed and then randomly split into 20% test and 80% training sets. To determine the parameter of how many neighbors to consider, K, I would start by testing a wide range of values, like between 1 and 50, and comparing performance on the training and test sets with a simple plot. From there, I would close onto the best K value based on where error and overfit (the difference in train and test performance) is low. To better generalize the model, k-fold cross validation can be used.\n",
    "\n",
    "Multiple resampling of the test/train set can be used to assess the model. Ideally, the results should not show high fluctuation in performance when trying different sets. Given that the classes have been balanced, a confusion matrix can be used to see overall accuracies and reveal any specific classes that the model has trouble identifying. If false positives are a concern, precision, recall and F1 scores can also be considered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
